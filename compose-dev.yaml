name: open-webui-dev

services:

  frontend:
    build:
      context: .
      target: build
    command: ["npm", "run", "dev"]
    depends_on:
      - backend
    extra_hosts:
      - host.docker.internal:host-gateway
    ports:
      - "3000:5173"
    network_mode: host
    develop:
      watch:
        - action: sync
          path: ./src
          target: /app/src
        - action: rebuild
          path: package.json

  backend:
    build:
      context: .
      target: base
    command: ["bash", "dev.sh"]
    env_file: ".env"
    depends_on:
     - litellm 
    environment:
     - ENV=dev
     - WEBUI_AUTH=False
     - OLLAMA_API_BASE_URL=http://host.docker.internal:11434
     - OPENAI_API_BASE_URLS=http://0.0.0.0:4000/v1
    volumes:
      - data:/app/backend/data
    extra_hosts:
      - host.docker.internal:host-gateway
    ports:
      - "8080:8080"
    restart: no
    network_mode: host
    develop:
      watch:
        - action: sync
          path: ./backend
          target: /app/backend
          ignore:
            - backend/data
        - action: rebuild
          path: backend/requirements.txt

  litellm:
    image: ghcr.io/berriai/litellm:main-stable
    volumes:
      - ${PWD}/litellm_config.yml:/app/config.yml
    ports:
      - "4000:4000" # Map the container port to the host, change the host port if necessary
    command: ["--config", "/app/config.yml", "--detailed_debug"]
    env_file:
      - .litellm.env # Load local .env file 

volumes:
  data: {}